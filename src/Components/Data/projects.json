[
  {
    "id": 1,
    "title": "Data Processing and Storage Pipeline for E-Commerce Behavior Data",
    "description": "This project involves building a big data pipeline to source, process, and visualize data. The pipeline consists of multiple steps, including data sourcing using Python, Kafka for data streaming, Apache Spark for ETL processing, and Tableau for data visualization.",
    "technologies": [
      "Apache Kafka",
      "AWS",
      "Apache Spark",
      "Tableau",
      "ETL",
      "Batch Processing"
    ],
    "image": "./projectImages/bdArchitecture.png",
    "link": "https://github.com/Pradyothsp/bd-pipeline"
  },
  {
    "id": 2,
    "title": "World Energy Consumption Visualized",
    "description": "The 'World Energy Consumption Visualized' project uses interactive visualizations to explore the dynamic connection between global energy consumption and economic prosperity, offering insights through D3.js and Our World in Data's dataset.",
    "technologies": [
      "d3.js",
      "Git",
      "HTML/CSS",
      "Pandas"
    ],
    "image": "./projectImages/energyConsumption.png",
    "link": "https://github.com/Pradyothsp/dv-world-energy-consumption"
  },
  {
    "id": 3,
    "title": "Backorder Prediction",
    "description": "I built a high-performing Backorder Prediction System using machine learning. It accurately forecasts stock shortages (90% accuracy) and offers user-friendly interfaces for both individual product checks and bulk prediction via CSV files. The system leverages industry-standard tools like Django and scikit-learn for efficient development and deployment.",
    "technologies": [
      "Django",
      "Docker",
      "GitLab CI/CD",
      "Django ORM",
      "Model Building"
    ],
    "image": "./projectImages/backorderPredictionPredict.png",
    "link": "https://gitlab.com/Pradyothsp/backorder-prediction"
  },
  {
    "id": 4,
    "title": "Person Detection Using Embarrassingly Parallel Computing",
    "description": "This project utilizes parallel processing to improve pedestrian detection in videos. It leverages a pre-trained YOLOv3 model for object detection and harnesses the power of multi-core processors for faster frame processing. The system is designed to be scalable, allowing for efficient processing of large video datasets.",
    "technologies": [
      "Object Detection",
      "PyTorch",
      "YOLOv3",
      "OpenCV",
      "Parallel Computing",
      "Linux"
    ],
    "image": "./projectImages/parallelPersonDetection.png",
    "link": "https://github.com/Pradyothsp/person-detection-using-embarrassingly-parallel-computating"
  },
  {
    "id": 5,
    "title": "Customer Segmentation Clustering",
    "description": "This project aims to use k-means and Agglomerative clustering to segment customers into different groups based on their characteristics and purchasing habits. The goal is to understand the similarities and differences between the customer segments, which can help inform marketing strategies and target specific groups of customers.",
    "technologies": [
      "Python",
      "K-means",
      "Agglomerative Clustering",
      "PCA",
      "Feature Engineering"
    ],
    "image": "./projectImages/customersClusters.png",
    "link": "https://github.com/Pradyothsp/Customer_Segmentation_Clustering"
  }
]